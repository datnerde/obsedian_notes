- Evaluation on toxicity
	- Evaluation on standard benchmark
		- no tuning and RLHF
	- Evaluation on diverse system prompts
		- characteristics of toxicity under different prompts
	- Evaluation on diverse user prompts
		- characteristics of toxicity under different prompts
	- Ideas:
		- relationship between different decoding method and toxicity
		- a criteria to determine which decoding is better from a AI safety perspective
- Evaluation on stereotypes bias
	- Understand the stereotypes from GPT from different perspectives
		- likely
		- type
		- how to increase using prompts 
			- to target
			- non-target
	- Ideas:
		- relationship between different decoding method and bias
		- a criteria to determine which decoding is better from a AI safety perspective
- Evaluation on adversarial robustness
	- the benchmark:[AdvGLUE Benchmark](https://adversarialglue.github.io/)
	- benchmark evaluation
	- focus on subset of evaluation and enhance those attack (the dataset is not released yet)
- Evaluation on out-of-distribution robustness
	- OOD 就是给的数据和训练数据完全不一样咋办
	- 各种style 变形
		- 换文字风格啥的
	- 时间上的限制
	- in context learning settings
		- 给的跟测得有差
- Evaluation on robustness against adversarial demonstrations
	- counterfactual demonstrations
	- spurious correlation
	- backdoors attacks
- Evaluation on privacy
	- evaluate in traniing set
	- evalute in in context learning
	- evalute with privacy workd

- 好的decoding method能让LLM产生的结果更多样更自然更贴合人的说话方式
	- 那会不会相应的多了的风险呢？
	- 如何衡量这些风险？
		- out-of-distribution robustness
			- 我们的的假设是好的decoding method应该更robust
			- 因为对于不同于模型遇见的数据集，结果更多样的decoding method应该会更容易涵盖edge case?
		- adversarial robustness （感觉这个相对好做因为有现成的数据集）
			- same above
			- 好的decoding method less greedy, less sensitive to probability, 更有可能选到小概率的词汇，更不容易收到这些负面攻击的影响
		- robustness against adversarial demonstrations
			- same as above
			- 可能对于in-context learning来说，decoding的选择影响不大